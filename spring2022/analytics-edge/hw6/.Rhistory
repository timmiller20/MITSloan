specific_user <- impute(fit, specific_user$userID, music.test$songID, unscale = TRUE)
# Packages
library(softImpute)
library(dplyr)
library(tidyr)
library(ggplot2)
# Reading the function file
source("functionsCF.R")
setwd("~/GitHub/MITSloan/spring2022/analytics-edge/hw6")
# Packages
library(softImpute)
library(dplyr)
library(tidyr)
library(ggplot2)
# Reading the function file
source("functionsCF.R")
# Read data
songs <- read.csv("Songs.csv")
users <- read.csv("Users.csv")
music <- read.csv("MusicRatings.csv")
# Train/test split
set.seed(331)
training.rows <- cf.training.set(music$userID, music$songID, prop=0.92)
music.train <- music[training.rows,]
music.test <- music[-training.rows,]
mat.train <- Incomplete(music.train[,1], music.train[,2], music.train[,3])
# test value is correct
mean(music.train$rating)
# Center matrix
set.seed(138)
mat.scaled <- biScale(mat.train, maxit=1000, row.scale = FALSE, col.scale = FALSE)
# Evaluate ranks
set.seed(789)
rank.info <- cf.evaluate.ranks(music.train, 0:7, prop.validate=0.05)
plot(rank.info$rank, rank.info$r2, type = "l", ylab = "R^2", xlab = "rank")
# Fit collaborative model using center matrix
set.seed(157)
fit <- softImpute(mat.scaled, rank.max=3, lambda=0, maxit=1000)
# Make out-of-sample prediction
pred_outsample_0 <- impute(fit, music.test$userID, music.test$songID, unscale = TRUE)
# Evaluate ranks
set.seed(789)
rank.info <- cf.evaluate.ranks(music.train, 0:7, prop.validate=0.05)
plot(rank.info$rank, rank.info$r2, type = "l", ylab = "R^2", xlab = "rank")
# Train/test split
set.seed(331)
training.rows <- cf.training.set(music$userID, music$songID, prop=0.92)
music.train <- music[training.rows,]
music.test <- music[-training.rows,]
mat.train <- Incomplete(music.train[,1], music.train[,2], music.train[,3])
# test value is correct
mean(music.train$rating)
# Center matrix
set.seed(138)
mat.scaled <- biScale(mat.train, maxit=1000, row.scale = FALSE, col.scale = FALSE)
# Evaluate ranks
set.seed(789)
rank.info <- cf.evaluate.ranks(music.train, 0:7, prop.validate=0.05)
plot(rank.info$rank, rank.info$r2, type = "l", ylab = "R^2", xlab = "rank")
rank.info
mat.scaled <- biScale(mat.train, maxit=1000, row.scale = FALSE, col.scale = FALSE)
# Evaluate ranks
set.seed(789)
rank.info <- cf.evaluate.ranks(music.train, 0:7, prop.validate=0.05)
plot(rank.info$rank, rank.info$r2, type = "l", ylab = "R^2", xlab = "rank")
# Packages
library(softImpute)
library(dplyr)
library(tidyr)
library(ggplot2)
# Reading the function file
source("functionsCF.R")
# Read data
songs <- read.csv("Songs.csv")
users <- read.csv("Users.csv")
music <- read.csv("MusicRatings.csv")
# Train/test split
set.seed(331)
training.rows <- cf.training.set(music$userID, music$songID, prop=0.92)
music.train <- music[training.rows,]
music.test <- music[-training.rows,]
mat.train <- Incomplete(music.train[,1], music.train[,2], music.train[,3])
# test value is correct
mean(music.train$rating)
# Center matrix
set.seed(138)
mat.scaled <- biScale(mat.train, maxit=1000, row.scale = FALSE, col.scale = FALSE)
# Evaluate ranks
set.seed(789)
rank.info <- cf.evaluate.ranks(music.train, 0:7, prop.validate=0.05)
plot(rank.info$rank, rank.info$r2, type = "l", ylab = "R^2", xlab = "rank")
# Fit collaborative model using center matrix
set.seed(157)
fit <- softImpute(mat.scaled, rank.max=3, lambda=0, maxit=1000)
# Make out-of-sample prediction
pred_outsample_0 <- impute(fit, music.test$userID, music.test$songID, unscale = TRUE)
# look at distribution
hist(pred_outsample_0)
#set min of 1 and max of 4
pred_outsample <- pmax(pmin(pred_outsample_0, 4), 1)
#check updated output and confirm bounds
hist(pred_outsample)
# Calculate osr^2
R2_outsample <- 1 - sum((pred_outsample-music.test$rating)^2)/sum((mean(music.test$rating) - music.test$rating)^2)
R2_outsample
# Fit collaborative model using center matrix
set.seed(157)
fit <- softImpute(mat.scaled, rank.max=2, lambda=0, maxit=1000)
# Make out-of-sample prediction
pred_outsample_0 <- impute(fit, music.test$userID, music.test$songID, unscale = TRUE)
# look at distribution
hist(pred_outsample_0)
#set min of 1 and max of 4
pred_outsample <- pmax(pmin(pred_outsample_0, 4), 1)
#check updated output and confirm bounds
hist(pred_outsample)
# Calculate osr^2
R2_outsample <- 1 - sum((pred_outsample-music.test$rating)^2)/sum((mean(music.test$rating) - music.test$rating)^2)
R2_outsample
# add score from archetype 1
songs$score1 = fit$v[,1]
# add score from archetype 2
songs$score2 = fit$v[,2]
# Score differences
songs$diff = songs$score1 - songs$score2
# Top 10 greatest negative difference
head(songs[order(songs$diff),], 10)
# Top 10 greatest positive difference
head(songs[order(-songs$diff),], 10)
# test value is correct
mean(music.train$rating)
# aggregate difference by artist
artist_diff = aggregate(songs$diff, by=list(songs$artist), FUN=sum)
# aggregate by number of songs per artist
song_count = aggregate(songs$artist, by=list(songs$artist), FUN=length)
# filter for artists with 4 songs
songs_min = song_count[which(song_count[,2]>=4),]
#confirm correct filtering
songs_min[order(-songs_min$x),]
# filter for artists with 4 or more songs
artist_diff_2 = filter(artist_diff,
Group.1 %in% songs_min$Group.1)
# Top 5 greatest negative difference
head(artist_diff_2[order(artist_diff_2$x),], 5)
# Top 5 greatest positive difference
head(artist_diff_2[order(-artist_diff_2$x),], 5)
# Fit collaborative model using center matrix
set.seed(157)
fit <- softImpute(mat.scaled, rank.max=3, lambda=0, maxit=1000)
# Make out-of-sample prediction
pred_outsample_0 <- impute(fit, music.test$userID, music.test$songID, unscale = TRUE)
# look at distribution
hist(pred_outsample_0)
#set min of 1 and max of 4
pred_outsample <- pmax(pmin(pred_outsample_0, 4), 1)
#check updated output and confirm bounds
hist(pred_outsample)
# Calculate osr^2
R2_outsample <- 1 - sum((pred_outsample-music.test$rating)^2)/sum((mean(music.test$rating) - music.test$rating)^2)
# add score from archetype 1
songs$score1 = fit$v[,1]
R2_outsample
# add score from archetype 1
songs$score1 = fit$v[,1]
# add score from archetype 2
songs$score2 = fit$v[,2]
# Score differences
songs$diff = songs$score1 - songs$score2
# Top 10 greatest negative difference
head(songs[order(songs$diff),], 10)
# Top 10 greatest positive difference
head(songs[order(-songs$diff),], 10)
# Fit collaborative model using center matrix
set.seed(157)
fit <- softImpute(mat.scaled, rank.max=2, lambda=0, maxit=1000)
# Make out-of-sample prediction
pred_outsample_0 <- impute(fit, music.test$userID, music.test$songID, unscale = TRUE)
# look at distribution
hist(pred_outsample_0)
#set min of 1 and max of 4
pred_outsample <- pmax(pmin(pred_outsample_0, 4), 1)
#check updated output and confirm bounds
hist(pred_outsample)
# Calculate osr^2
R2_outsample <- 1 - sum((pred_outsample-music.test$rating)^2)/sum((mean(music.test$rating) - music.test$rating)^2)
R2_outsample
# Fit collaborative model using center matrix
set.seed(157)
# Make out-of-sample prediction
pred_outsample_0 <- impute(fit, music.test$userID, music.test$songID, unscale = TRUE)
fit <- softImpute(mat.scaled, rank.max=2, lambda=0, maxit=1000)
# Make out-of-sample prediction
pred_outsample_0 <- impute(fit, music.test$userID, music.test$songID, unscale = TRUE)
# look at distribution
hist(pred_outsample_0)
#set min of 1 and max of 4
pred_outsample <- pmax(pmin(pred_outsample_0, 4), 1)
#check updated output and confirm bounds
hist(pred_outsample)
# Calculate osr^2
R2_outsample <- 1 - sum((pred_outsample-music.test$rating)^2)/sum((mean(music.test$rating) - music.test$rating)^2)
R2_outsample
# Evaluate ranks
set.seed(789)
rank.info <- cf.evaluate.ranks(music.train, 0:7, prop.validate=0.05)
rank.info
plot(rank.info$rank, rank.info$r2, type = "l", ylab = "R^2", xlab = "rank")
# add score from archetype 1
songs$score1 = fit$v[,1]
# add score from archetype 2
songs$score2 = fit$v[,2]
# Score differences
songs$diff = songs$score1 - songs$score2
# Top 10 greatest negative difference
head(songs[order(songs$diff),], 10)
# Top 10 greatest positive difference
head(songs[order(-songs$diff),], 10)
# aggregate difference by artist
artist_diff = aggregate(songs$diff, by=list(songs$artist), FUN=sum)
# aggregate by number of songs per artist
song_count = aggregate(songs$artist, by=list(songs$artist), FUN=length)
# filter for artists with 4 songs
songs_min = song_count[which(song_count[,2]>=4),]
#confirm correct filtering
songs_min[order(-songs_min$x),]
# filter for artists with 4 or more songs
artist_diff_2 = filter(artist_diff,
Group.1 %in% songs_min$Group.1)
# Top 5 greatest negative difference
head(artist_diff_2[order(artist_diff_2$x),], 5)
# Top 5 greatest positive difference
head(artist_diff_2[order(-artist_diff_2$x),], 5)
fit
fit$u
fit$v
fit$d
head(fit$v %*% diag(fit$d))
specific_user = music[which(music[,1]==1089),]
specific_user
specific_user <- impute(fit, specific_user$userID, specific_user$songID, unscale = TRUE)
specific_user
specific_user <- impute(fit, music$userID, music$songID, unscale = TRUE)
specific_user
specific_user <- impute(fit, music$userID == 1089, music$songID, unscale = TRUE)
?impute
pred_outsample_0
pred_outsample_0[,1]
music.test
pred_outsample
